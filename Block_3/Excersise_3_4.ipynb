{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:white;background-color:rgb(255, 108, 0);padding-top:1em;padding-bottom:0.7em;padding-left:1em;\">Excersise 3.4 solution</h1>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test data\n",
    "test_data = np.arange(0,1,0.01)\n",
    "\n",
    "#Load data and plot\n",
    "inputs,labels = np.load('SIT_visit/Block_3/data/data.npy')\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(inputs, labels, color='black')\n",
    "plt.xlabel('x', fontsize=12)\n",
    "plt.ylabel('y', fontsize=12)\n",
    "plt.title('Training data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data pipeline:\n",
    "batch_size = 100\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "ds = tf.data.Dataset.from_tensor_slices((inputs,labels)).shuffle(len(labels)).repeat().batch(batch_size)\n",
    "\n",
    "iterator = ds.make_initializable_iterator()\n",
    "iterator_init = iterator.initializer\n",
    "\n",
    "inps,labs = iterator.get_next()\n",
    "inps = tf.reshape(inps, [-1,1], name='inputs')\n",
    "labs = tf.reshape(labs, [-1,1], name='labels')\n",
    "\n",
    "\n",
    "#Neural network model:\n",
    "def net(x, layer_sizes=[10,10,1], reuse=False, name='FC'):\n",
    "    with tf.variable_scope(name, reuse=reuse):\n",
    "        hidden_1 = tf.layers.dense(x, layer_sizes[0], activation=tf.nn.tanh, name='hidden_layer_1')\n",
    "        hidden_2 = tf.layers.dense(hidden_1, layer_sizes[1], activation=tf.nn.tanh, name='hidden_layer_2')\n",
    "        output = tf.layers.dense(hidden_2, layer_sizes[2], name='output_layer')\n",
    "        return output\n",
    "\n",
    "predictions = net(inps)\n",
    "predictions = tf.identity(predictions, name='predictions')\n",
    "\n",
    "extra_pred = net(inps, layer_sizes=[20,20,6], name='Extra')\n",
    "extra_pred = tf.identity(extra_pred, name='extra_pred')\n",
    "par = tf.reduce_mean(extra_pred, axis=0)\n",
    "\n",
    "#Loss function and optimization:\n",
    "loss = tf.identity(tf.losses.mean_squared_error(labels=labs, predictions=predictions), name='loss')\n",
    "\n",
    "extra_func = par[0]*tf.sin(par[1]*inps+par[2])**2+par[3]*tf.sin(par[4]*inps+par[5])\n",
    "extra_loss = tf.identity(tf.losses.mean_squared_error(labels=labs, predictions=extra_func), name='extra_loss')\n",
    "\n",
    "train_step = tf.train.AdamOptimizer(0.1).minimize(loss)\n",
    "extra_train_step = tf.train.AdamOptimizer(0.1).minimize(extra_loss)\n",
    "\n",
    "variable_init = tf.global_variables_initializer()\n",
    "\n",
    "\n",
    "#Training process and evaluation:\n",
    "train = True\n",
    "losses = []\n",
    "extra_losses = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run([iterator_init,variable_init])\n",
    "    c = 0\n",
    "    while train:\n",
    "        l,_ = sess.run([loss, train_step])\n",
    "        print('Batch:', c, 'loss:', l)\n",
    "        c += 1\n",
    "        if l < 0.002 or c > 1000:\n",
    "            train = False\n",
    "        losses.append(l)\n",
    "    print('\\nEnd of training process\\n')\n",
    "    p = sess.run(predictions, feed_dict={inps: np.reshape(inputs,[-1,1])})\n",
    "    for j in range(len(inputs)):\n",
    "        print('\\nInputs:', inputs[j], 'prediction:', p[j][0], 'correct label:', labels[j])\n",
    "    \n",
    "    print('Extra task:')\n",
    "    c = 0\n",
    "    train = True\n",
    "    while train:\n",
    "        params,l,_ = sess.run([par,extra_loss, extra_train_step])\n",
    "        print('Batch:', c, 'loss:', l)\n",
    "        c += 1\n",
    "        if l < 0.002 or c > 3000:\n",
    "            train = False\n",
    "        extra_losses.append(l)\n",
    "    print('\\nEnd of extra task\\nPredicted params:', params)\n",
    "\n",
    "\n",
    "x = np.arange(0,1,0.01)\n",
    "y = params[0]*np.sin(params[1]*x+params[2])**2+params[3]*np.sin(params[4]*x+params[5])\n",
    "\n",
    "#Evaluation\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(inputs, labels, label='Training data', color='black')\n",
    "ax.scatter(inputs,p, label='Predictions', color='green')\n",
    "ax.plot(x, y, label='Function with predicted params')\n",
    "plt.xlabel('x', fontsize=12)\n",
    "plt.ylabel('y', fontsize=12)\n",
    "plt.legend()\n",
    "plt.title('Evaluation')\n",
    "plt.show()\n",
    "\n",
    "#Real params 2,8,3,0.4,5,-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the losses\n",
    "plt.figure(1)\n",
    "plt.subplot(211)\n",
    "plt.plot(range(len(losses)), losses, label='Regression model loss')\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.title('Losses')\n",
    "#fig_2 = plt.figure(2)\n",
    "plt.subplot(212)\n",
    "plt.plot(range(len(extra_losses)), extra_losses, label='')\n",
    "plt.xlabel('Batch', fontsize=12)\n",
    "plt.ylabel('Extra task loss', fontsize=12)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
