{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:white;background-color:rgb(255, 108, 0);padding-top:1em;padding-bottom:0.7em;padding-left:1em;\">2.3 Deep Learning Theory</h1>\n",
    "<hr>\n",
    "\n",
    "<h2>Introduction</h2>\n",
    "\n",
    "We have seen how simple neural networks can be built and trained. In this lesson some other popular\n",
    "<br>\n",
    "neural network structures will be introduced briefly.\n",
    "\n",
    "<h3>Deep learning</h3>\n",
    "\n",
    "Deep learning is the area of machine learning algorithms that utilizes deep neural networks.\n",
    "<br>\n",
    "These networks are called deep because they many layers.\n",
    "\n",
    "In order to be able to talk about neural networks, first we have to introduce their terminology.\n",
    "<br>\n",
    "The neurons inside a neural network are organized into layers. One layer can consist of several neurons.\n",
    "<br>\n",
    "Those layers that does not produce the output are called hidden layers because their activations are hidden.\n",
    "<br>\n",
    "A neural network with multiple hidden layers are called deep neaural networks. The training, and usage of\n",
    "<br>\n",
    "such networks is referred to as deep learning.\n",
    "\n",
    "<h2>Fully connected networks</h2>\n",
    "\n",
    "In fully connected neural networks a single neuron in a layer takes the activation of all neurons in the previous layer as its input.\n",
    "<br>\n",
    "Fully connected networks are easy to understand, create and use. A very serious drawback of these networks is the\n",
    "<br>\n",
    "number of parameters needed for the network. Let's say we have 100 neurons in a layer and the previous layer\n",
    "<br>\n",
    "(or the inputs in case of the first hidden layer) consist of 100 values as well. In this case the number of parameters only for\n",
    "<br>\n",
    "that single layer would be 100x100 + 100 which is 10100 parameters (weights + biases for all neurons in the layer).\n",
    "<br>\n",
    "This way the number of parameters can rapidly increase to hundred thousands of millions.\n",
    "<br>\n",
    "The more parameters the model posesses the easier for it is to overfit. So we would like to keep the number of\n",
    "<br>\n",
    "parameters at the minimum not just because of the computational complexity and time costs, but because more parameters\n",
    "<br>\n",
    "would require more training data for the model not to overfit.\n",
    "\n",
    "<center>\n",
    "<br>\n",
    "Fully connected structure\n",
    "<br>\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1vp2JMShOQJXzFxYhqBIcjJuoAn6CzuYe\" width=\"30%\"/>\n",
    "</center>\n",
    "\n",
    "On the figure above a simple fully connected structure can be seen with two hidden layers, an output layer $(\\mathbf{o})$ and an input layer $(\\mathbf{i})$.\n",
    "\n",
    "<h2>Convolutional neural networks</h2>\n",
    "\n",
    "Convolutional neural networks ususally operate on volumes of data, like images that have width, height and depth\n",
    "<br>\n",
    "(depths are the color channels of the image). Convolutional neural networks use two special layers instead of the normal fully connected ones.\n",
    "<br>\n",
    "These special layers are the convolutional layer and the poolig layer. The convolotional layer utilizes local connections\n",
    "<br>\n",
    "with shared weights. The figure below shows a simple example of a convolutional layer with an input volume of (1,5,1),\n",
    "<br>\n",
    "two kernels of (1,3), stride of 1 and no padding.\n",
    "\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1980cUmSYjZa26iEDTGnmd2HIpoDzd-iQ\" width=\"30%\"/>\n",
    "\n",
    "The depth of the kernel is always equal to the depth of the input volume. A single bias value is used for each kernel.\n",
    "\n",
    "The pooling layer also uses kernels, but these kernels reduce the width and height of the input volume and not its depth.\n",
    "<br>\n",
    "A pooling kernel always have a unitary depth. The most popular function for pooling is the max pooling. In a max pooling layer\n",
    "<br>\n",
    "the output of the pooling operation will be the maximum element in the part of the volume that is joint with the pooling kernel.\n",
    "<br>\n",
    "Pooling kernels also have sizes of width and depth and stride and padding hyperparameters as well.\n",
    "\n",
    "Deep convolutional neural networks are often used as feature extractors for data with many dimensions, such as images.\n",
    "<br>\n",
    "A fully connected layer can process the features extracted by the convolutional structure.\n",
    "\n",
    "<h2>Recurrent neural networks</h2>\n",
    "\n",
    "Recurrent neural networks can have fully connected or convolutional layers as well. The specialty of this structure is that\n",
    "<br>\n",
    "it has spatial and temporal connections as well. The figure below shows a simple recurrent neural network structure and its\n",
    "<br>\n",
    "expansion along the time.\n",
    "\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1kauqLlFcchsFKrt82_rHrWOe5N-VJr1R\" width=\"50%\"/>\n",
    "\n",
    "Here $\\mathbf{i}_t$ is the input vector in the $i^{th}$ time step\n",
    "<br>\n",
    "$\\mathbf{h}_t$ is the hidden activation in the $i^{th}$ time step\n",
    "<br>\n",
    "$\\mathbf{o}_t$ is the output vector in the $i^{th}$ time step\n",
    "<br>\n",
    "$W_1, W_2, W_3$ are the weight matrices\n",
    "\n",
    "In order to train recurrent neural networks the Back-Propagation of the error also had to be done through time.\n",
    "<br>\n",
    "On the expanded image it can be seen, that a recurrent neural network can be interpreted as a very deep network,\n",
    "<br>\n",
    "depending on how far we look back for the training process."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
